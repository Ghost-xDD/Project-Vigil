# Vigil Intelligent Router

High-performance Go-based reverse proxy that intelligently routes Solana JSON-RPC requests to the optimal node using ML-powered predictions.

## üéØ Overview

The Vigil Intelligent Router acts as a smart gateway between clients and Solana RPC nodes. For each incoming request, it queries the ML Prediction Service to determine the healthiest, lowest-latency node and forwards the request accordingly.

### Architecture

```
Client ‚Üí Intelligent Router ‚Üí ML Service ‚Üí Recommended Node
           (Port 8080)          ‚Üì
                           Data Collector
                                ‚Üì
                        (Metrics & Health)
```

## üöÄ Features

- **ML-Powered Routing**: Real-time node selection based on ML predictions
- **High Performance**: Built in Go with concurrent request handling
- **Streaming**: Zero-copy response streaming for optimal latency
- **Fallback Support**: Automatic fallback to public RPC if ML service unavailable
- **Health Checks**: Built-in health endpoint for monitoring
- **Structured Logging**: JSON logging with zap for production observability
- **Graceful Shutdown**: Proper signal handling and connection draining
- **Docker Ready**: Containerized for easy deployment

## üì¶ Installation

### Prerequisites

- Go 1.21+
- Docker (optional)
- Access to ML Prediction Service
- Access to Data Collector Service

### Local Development

```bash
# Clone the repository
cd vigil-intelligent-router

# Install dependencies
go mod download

# Copy environment configuration
cp .env.example .env

# Edit .env with your settings
nano .env

# Build the application
go build -o vigil-router .

# Run the router
./vigil-router
```

### Using Docker

```bash
# Build Docker image
docker build -t vigil-intelligent-router .

# Run container
docker run -p 8080:8080 \
  -e ML_SERVICE_URL=http://ml-service:8001 \
  -e DATA_COLLECTOR_URL=http://data-collector:8000 \
  vigil-intelligent-router
```

### Using Docker Compose (Recommended)

From the project root:

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f intelligent-router

# Stop services
docker-compose down
```

## üîß Configuration

Configuration is done via environment variables:

| Variable                   | Description                              | Default                          |
| -------------------------- | ---------------------------------------- | -------------------------------- |
| `ROUTER_PORT`              | Port to listen on                        | `8080`                           |
| `ROUTER_HOST`              | Host to bind to                          | `0.0.0.0`                        |
| `ML_SERVICE_URL`           | ML Prediction Service base URL           | `http://localhost:8001`          |
| `ML_PREDICT_ENDPOINT`      | ML prediction endpoint path              | `/predict`                       |
| `DATA_COLLECTOR_URL`       | Data Collector Service URL               | `http://localhost:8000`          |
| `METRICS_ENDPOINT`         | Metrics endpoint path                    | `/api/v1/metrics/latest-metrics` |
| `FALLBACK_RPC_URL`         | Fallback RPC URL                         | `https://api.devnet.solana.com`  |
| `FALLBACK_ENABLED`         | Enable fallback on ML failure            | `true`                           |
| `REQUEST_TIMEOUT_SECONDS`  | RPC request timeout                      | `30`                             |
| `ML_QUERY_TIMEOUT_SECONDS` | ML query timeout                         | `5`                              |
| `LOG_LEVEL`                | Logging level (debug, info, warn, error) | `info`                           |
| `LOG_FORMAT`               | Log format (json or console)             | `json`                           |
| `HEALTH_CHECK_ENABLED`     | Enable health check endpoint             | `true`                           |

## üì° API Endpoints

### POST /rpc

Main endpoint for Solana JSON-RPC requests.

**Request:**

```bash
curl -X POST http://localhost:8080/rpc \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "id": 1,
    "method": "getHealth"
  }'
```

**Response:**
The response from the selected Solana RPC node is streamed directly back.

**Process:**

1. Router receives request
2. Queries ML service for best node
3. Forwards request to recommended node
4. Streams response back to client

### GET /health

Health check endpoint.

**Response:**

```json
{
  "status": "healthy",
  "service": "vigil-intelligent-router",
  "time": "2023-10-25T12:00:00Z"
}
```

### GET /

Service information.

**Response:**

```json
{
  "service": "Vigil Intelligent Router",
  "version": "1.0.0",
  "endpoints": {
    "rpc": "/rpc",
    "health": "/health"
  },
  "description": "ML-powered intelligent routing for Solana RPC requests"
}
```

## üîÑ Request Flow

```
1. Client sends RPC request
   ‚Üì
2. Router queries ML service with current metrics
   ‚Üì
3. ML service returns recommended node (e.g., "helius_devnet")
   ‚Üì
4. Router resolves node ID to RPC URL
   ‚Üì
5. Router forwards request to selected node
   ‚Üì
6. Router streams response back to client
```

## üìä Logging

The router provides structured logging with the following fields:

```json
{
  "level": "info",
  "ts": 1698235200.123,
  "msg": "Routing to recommended node",
  "node": "helius_devnet",
  "url": "https://devnet.helius-rpc.com",
  "failure_prob": 0.08,
  "predicted_latency": 120.5,
  "cost_score": 0.125
}
```

### Log Levels

- **DEBUG**: Detailed diagnostic information
- **INFO**: General operational messages (default)
- **WARN**: Warning messages for degraded functionality
- **ERROR**: Error messages for failed operations

## üîê Production Considerations

### Security

1. **API Keys**: Store RPC API keys securely (environment variables or secrets management)
2. **Rate Limiting**: Implement rate limiting at the load balancer level
3. **HTTPS**: Deploy behind a reverse proxy (nginx/Traefik) with TLS
4. **Authentication**: Add authentication layer for client requests if needed

### Performance

- **Connection Pooling**: Configured with 100 max idle connections
- **Timeouts**: Configurable timeouts prevent hanging requests
- **Streaming**: Zero-copy streaming minimizes memory usage
- **Goroutines**: Concurrent handling of multiple requests

### Monitoring

Add Prometheus metrics:

```go
// Example metrics to add
var (
    requestsTotal = prometheus.NewCounterVec(...)
    requestDuration = prometheus.NewHistogramVec(...)
    mlQueryDuration = prometheus.NewHistogram(...)
)
```

### High Availability

1. **Multiple Instances**: Run multiple router instances behind a load balancer
2. **Health Checks**: Use `/health` endpoint for load balancer health checks
3. **Graceful Shutdown**: Built-in support for graceful connection draining
4. **Fallback**: Automatic fallback to public RPC ensures availability

## üêõ Troubleshooting

### ML Service Connection Failed

```
Error: ML service query failed
```

**Solutions:**

- Verify ML service is running: `curl http://localhost:8001/health`
- Check `ML_SERVICE_URL` configuration
- Ensure network connectivity between services
- Enable fallback: `FALLBACK_ENABLED=true`

### Request Timeout

```
Error: Failed to reach RPC node
```

**Solutions:**

- Increase `REQUEST_TIMEOUT_SECONDS`
- Check target RPC node availability
- Verify network connectivity
- Review firewall rules

### High Latency

**Causes:**

- ML service response time
- Target RPC node performance
- Network latency

**Solutions:**

- Monitor ML service performance
- Adjust `ML_QUERY_TIMEOUT_SECONDS`
- Check RPC node status
- Consider caching ML recommendations (advanced)

## üìà Performance Benchmarks

Typical performance metrics:

- **Throughput**: 1000+ requests/second
- **Latency Overhead**: ~5-50ms (ML query + routing logic)
- **Memory Usage**: ~20-50MB per instance
- **CPU Usage**: Minimal (<5% on modern hardware)

## üß™ Testing

### Unit Tests

```bash
go test ./... -v
```

### Integration Tests

```bash
# Ensure all services are running
docker-compose up -d

# Test RPC endpoint
curl -X POST http://localhost:8080/rpc \
  -H "Content-Type: application/json" \
  -d '{"jsonrpc":"2.0","id":1,"method":"getHealth"}'

# Test health endpoint
curl http://localhost:8080/health
```

### Load Testing

```bash
# Using hey
hey -n 1000 -c 10 -m POST \
  -H "Content-Type: application/json" \
  -d '{"jsonrpc":"2.0","id":1,"method":"getHealth"}' \
  http://localhost:8080/rpc
```

## üîÑ Development

### Project Structure

```
vigil-intelligent-router/
‚îú‚îÄ‚îÄ config/           # Configuration management
‚îÇ   ‚îî‚îÄ‚îÄ config.go
‚îú‚îÄ‚îÄ ml/              # ML service client
‚îÇ   ‚îî‚îÄ‚îÄ client.go
‚îú‚îÄ‚îÄ proxy/           # Proxy handler logic
‚îÇ   ‚îî‚îÄ‚îÄ handler.go
‚îú‚îÄ‚îÄ main.go          # Application entry point
‚îú‚îÄ‚îÄ Dockerfile       # Docker build config
‚îú‚îÄ‚îÄ go.mod          # Go dependencies
‚îî‚îÄ‚îÄ README.md       # This file
```

### Adding New Features

1. Fork the repository
2. Create a feature branch
3. Implement changes with tests
4. Update documentation
5. Submit pull request

## üìÑ License

MIT License - see LICENSE file

## ü§ù Contributing

Contributions welcome! Please:

1. Follow Go best practices
2. Add tests for new features
3. Update documentation
4. Use conventional commits

## üìû Support

- **Issues**: Open an issue on GitHub
- **Logs**: Check logs with `docker-compose logs intelligent-router`
- **Health**: Monitor `/health` endpoint

## üîó Related Services

- **Data Collector** (Port 8000): Collects RPC node metrics
- **ML Prediction Service** (Port 8001): Provides routing recommendations

---

Built with ‚ù§Ô∏è in Go for the Solana ecosystem
